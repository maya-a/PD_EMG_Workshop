{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "from scipy import stats\n",
    "from scipy.stats import zscore\n",
    "from mne.preprocessing import peak_finder\n",
    "from pipeline import CleaningPipe, ICAPipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "control = ['AA4',  'AD5', 'AD7',  'BP5',  'BZ4', \n",
    "           'DC9',  'KS6', 'LK4',  'LS8',  'MG1',\n",
    "           'MK39', 'ML6', 'MU6',  'OS8',  'RA64', \n",
    "           'RS2', 'SA50', 'TBN8', 'VB10', 'YL02']\n",
    "parkinsons = ['AC4',  'AH67', 'AP7', 'AS98', 'ED8',\n",
    "              'HR67', 'MM4',  'NF1', 'RK4',  'RT1', \n",
    "              'SA7',  'SB2',  'TY0', 'VH5',  'VP2',\n",
    "              'YAA0', 'YG2',  'YG8', 'YH8' , 'YP8',\n",
    "              'YZ6',  'YZ64', 'ZZ0']\n",
    "\n",
    "groups = [control, parkinsons]\n",
    "group_names = ['control', 'parkinsons']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed = []\n",
    "success = []\n",
    "for num, group in enumerate(groups):\n",
    "    for id in group:\n",
    "        pipe = CleaningPipe(\n",
    "            file=rf\"D:\\eeg\\maya\\data\\subjects\\{group_names[num]}\\{id}\\{id}.mff\",\n",
    "            output_directory=rf\"D:\\eeg\\maya\\data\\subjects\\{group_names[num]}\\{id}\\outputs\",)\n",
    "        try:\n",
    "            pipe.resample(sfreq=250,save=True)\n",
    "            success.append(id)\n",
    "        except:\n",
    "            failed.append(id)\n",
    "print(len(failed), \" failed:\", failed)\n",
    "print(len(success),\" succeeded:\", success)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_file = []\n",
    "no_filter = []\n",
    "\n",
    "for num, group in enumerate(groups):    \n",
    "    for id in group:\n",
    "        pipe = 0\n",
    "        try:\n",
    "            pipe = CleaningPipe(\n",
    "                path_to_eeg=rf\"D:\\eeg\\maya\\data\\subjects\\control\\{id}\\resampled_250\\saved_raw\\resampled_250hz_raw.fif\",\n",
    "                output_directory=rf\"D:\\eeg\\maya\\data\\subjects\\control\\{id}\")    \n",
    "        except:\n",
    "            no_file.append(id)\n",
    "            del pipe\n",
    "            continue\n",
    "        try:\n",
    "            pipe.filter(l_freq = 10, h_freq=100, savefig=False)\n",
    "            pipe.notch()\n",
    "            pipe._save_raw('EMG_filter.fif')\n",
    "            success.append(id)\n",
    "        except:\n",
    "            no_filter.append(id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction of facial Electrodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = ['E94', 'E190', #reference points\n",
    "          'E226', 'E230', 'E234', \n",
    "          'E235', 'E238', 'E239', 'E240', \n",
    "          'E241', 'E242', 'E243', 'E244', \n",
    "          'E245', 'E248', 'E252']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fail = []\n",
    "success = []\n",
    "for i, group in enumerate(groups):\n",
    "    for id in group:\n",
    "        pipe = 0\n",
    "        try: \n",
    "            pipe = CleaningPipe(path_to_eeg=rf\"D:\\eeg\\maya\\data\\subjects\\{group_names[i]}\\{id}\\saved_raw\\EMG_filter.fif\")\n",
    "            pipe.mne_raw.save(rf\"D:\\eeg\\maya\\data\\EMG\\REM_Segments_new\\{group_names[i]}\\{id}\\filtered_subset_raw.fif\", picks = subset)\n",
    "            success.append(id)\n",
    "        except:\n",
    "            print(rf\"couldn't save {id}'s subset\")\n",
    "            fail.append(id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction of REM Segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_count(group, id):\n",
    "    count = 0\n",
    "    dir_path =rf\"D:\\eeg\\maya\\data\\EMG\\REM_Segments\\{group}\\{id}\\REM_segment_{count}_raw.fif\"\n",
    "    while (os.path.exists(dir_path)):\n",
    "        count+=1\n",
    "        dir_path =rf\"D:\\eeg\\maya\\data\\EMG\\REM_Segments\\{group}\\{id}\\REM_segment_{count}_raw.fif\"\n",
    "    return count-1\n",
    "\n",
    "def belongs(stages, mark):\n",
    "    for i in range(len(stages)):\n",
    "        if (mark == stages[i]):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage = [4] # An array that contains the desired stages of sleep\n",
    "          #0 : WAKE \n",
    "          #1 : N1   \n",
    "          #2 : N2  \n",
    "          #3 : N3   \n",
    "          #4 : REM  \n",
    "fail = []\n",
    "success = []\n",
    "for i, group in enumerate(groups):\n",
    "    for id in group:\n",
    "        pipe = 0\n",
    "        try:\n",
    "            fname = rf\"D:\\eeg\\maya\\data\\EMG\\ICA\\REM_Segments\\{group_names[i]}\\{id}\\filtered_subset_raw.fif\"\n",
    "            raw = mne.io.read_raw_fif(fname, verbose = 'ERROR') \n",
    "            #print(\"----- Getting EMG (data) -----\")\n",
    "            data = raw.get_data()\n",
    "            raw.load_data()\n",
    "            #print(\"----- Reading Hypnospectogram (stages) -----\")\n",
    "            stages = np.loadtxt(rf\"D:\\eeg\\maya\\data\\subjects\\{group_names[i]}\\{id}\\{id}_staging.txt\", dtype=int)\n",
    "            last = stages[-1]\n",
    "            pad = data.shape[1] - stages.shape[0]\n",
    "            if pad < 0:\n",
    "                stages = stages[:data.shape[1]]\n",
    "\n",
    "                indexes = [i for i in range(len(stages)) if belongs(stage, stages[0][i])]\n",
    "            else:\n",
    "                stages.shape = (1,stages.shape[0])\n",
    "                padding = np.full(pad, last)\n",
    "                padding.shape = (1,padding.shape[0])\n",
    "                stages = np.concatenate([stages,padding],axis = 1)\n",
    "                indexes = [i for i in range(stages.shape[1]) if belongs(stage, stages[0][i])]\n",
    "            \n",
    "            #print(\"----- Extracting REM Ranges -----\")\n",
    "            REM_ranges = []\n",
    "            start = indexes[0]\n",
    "            end = indexes[1499]\n",
    "            for k in range(1500, len(indexes), 1500):\n",
    "                if k + 1499 < len(indexes):\n",
    "                    end_index = k + 1499\n",
    "                else:\n",
    "                    end_index = len(indexes) - 1\n",
    "                if indexes[k] - indexes[k-1] == 1:\n",
    "                    end = indexes[end_index]\n",
    "                else:\n",
    "                    REM_ranges.append((start, end))\n",
    "                    start = indexes[k]\n",
    "                    end = indexes[end_index]\n",
    "            REM_ranges.append((start, end))\n",
    "            #print(\"----- Saving REM Ranges -----\")\n",
    "            for j,REM_range in enumerate(REM_ranges):\n",
    "                raw.save(rf\"D:\\eeg\\maya\\data\\EMG\\REM_Segments\\{group_names[i]}\\{id}\\segment_{j}_raw.fif\", \n",
    "                                tmin = REM_range[0]/250, \n",
    "                                tmax = REM_range[1]/250, verbose = 'ERROR')\n",
    "            success.append(id)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(rf\"couldn't segment {id}. recieved this error:\")\n",
    "            print(e)\n",
    "            fail.append(id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Channel Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_count(group, id, stage):\n",
    "    count = 0\n",
    "    dir_path =rf\"D:\\eeg\\maya\\data\\EMG\\{stage}_Segments\\{group}\\{id}\\segment_{count}_raw.fif\"\n",
    "    while (os.path.exists(dir_path)):\n",
    "        count+=1\n",
    "        dir_path =rf\"D:\\eeg\\maya\\data\\EMG\\{stage}_Segments\\{group}\\{id}\\segment_{count}_raw.fif\"\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_electrodes = ['E241', 'E242', 'E243', 'E244', 'E245', 'E248', 'E252']  #left facial electrodes names\n",
    "right_electrodes = ['E238', 'E239', 'E240', 'E234', 'E235', 'E230', 'E226'] #right facial electrodes names\n",
    "left_reference = 'E94'   #electrode names of the left mastoid\n",
    "right_reference = 'E190' #electrode name of the right mastoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A dictionary containing each referenced electrode and its corresponding coordinate location\n",
    "coordinates = {\n",
    "    'E226': [7.243, 4.801, -4.772],\n",
    "    'E230': [6.742, 5.991, -5.833],\n",
    "    'E234': [5.887, 7.227, -6.547],\n",
    "    'E235': [6.659, 5.641, -7.657],\n",
    "    'E238': [4.961, 8.227, -6.783],\n",
    "    'E239': [5.813, 6.421, -8.650],\n",
    "    'E240': [6.044, 5.371, -9.814],\n",
    "    'E241': [-4.961, 8.227, -6.783],\n",
    "    'E242': [-5.813, 6.421, -8.650],\n",
    "    'E243': [-6.044, 5.371, -9.814],\n",
    "    'E244': [-5.887, 7.227, -6.547],\n",
    "    'E245': [-6.659, 5.641, -7.657],\n",
    "    'E248': [-6.742, 5.991, -5.833],\n",
    "    'E252': [-7.243, 4.801, -4.772]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = [0, 0, 0]\n",
    "left_distances =[0]*7\n",
    "right = [0, 0, 0]\n",
    "right_distances =[0]*7\n",
    "for i in range(7):\n",
    "    for j in range(3):\n",
    "        left[j]+=(1/7)*coordinates[left_electrodes[i]][j]\n",
    "        right[j]+=(1/7)*coordinates[right_electrodes[i]][j]\n",
    "for i in range(7):\n",
    "    left_distances[i] = 1/np.linalg.norm(np.asarray(left)-np.asarray(coordinates[left_electrodes[i]]))\n",
    "    right_distances[i] = 1/np.linalg.norm(np.asarray(right)-np.asarray(coordinates[right_electrodes[i]]))\n",
    "left_weights = [i/sum(left_distances) for i in left_distances]\n",
    "right_weights = [i/sum(right_distances) for i in right_distances]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage = 'REM'\n",
    "for idx, group in enumerate(groups):\n",
    "    for id in group:\n",
    "        for segment_num in range(segment_count(group_names[idx],id, stage)):\n",
    "            fname = rf\"D:\\eeg\\maya\\data\\EMG\\{stage}_Segments\\{group_names[idx]}\\{id}\\segment_{segment_num}_raw.fif\"\n",
    "            raw = mne.io.read_raw_fif(fname, verbose='ERROR')\n",
    "            raw.load_data(verbose ='ERROR')\n",
    "\n",
    "            #Fetching Data\n",
    "            left = raw.copy().pick_channels(left_electrodes, verbose='ERROR')\n",
    "            left_ref = raw.copy().pick_channels([left_reference], verbose='ERROR')\n",
    "\n",
    "            right = raw.copy().pick_channels(right_electrodes, verbose='ERROR')\n",
    "            right_ref = raw.copy().pick_channels([right_reference], verbose ='ERROR')\n",
    "\n",
    "            left_data = left.get_data(verbose ='ERROR')\n",
    "            left_ref_data = left_ref.get_data(verbose ='ERROR')\n",
    "            right_data = right.get_data(verbose ='ERROR')\n",
    "            right_ref_data = right_ref.get_data(verbose ='ERROR')\n",
    "            \n",
    "            #Calculate channels\n",
    "            size = len(left_data[1])\n",
    "            left_channel = -1*(left_ref_data)\n",
    "            right_channel = -1*(right_ref_data)\n",
    "            for i in range(size):\n",
    "                for j in range(7):\n",
    "                    left_channel[0][i] += left_weights[j]*left_data[j][i]\n",
    "                    right_channel[0][i] += right_weights[j]*right_data[j][i]\n",
    "            \n",
    "            # Save channels to .fif file\n",
    "            ch_names = ['Left', 'Right']\n",
    "            ch_types = ['emg'] * 2\n",
    "            info = mne.create_info(ch_names, ch_types=ch_types, sfreq=250)\n",
    "            new_raw = mne.io.RawArray(np.vstack((left_channel, right_channel)), info, verbose='ERROR')\n",
    "            new_raw.save(rf\"D:\\eeg\\maya\\data\\EMG\\{stage}_Segments\\{group_names[idx]}\\{id}\\left_right\\channels_{segment_num}_raw.fif\", verbose = 'ERROR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 10 #sample length (in seconds)\n",
    "stages = ['REM'] #The array receives the stages the user wants to sample\n",
    "for stage in stages:    \n",
    "    for idx, group in enumerate(groups):\n",
    "        for id in group:\n",
    "            for segment_num in range(segment_count(group_names[idx],id, stage)): \n",
    "                fname = rf\"D:\\eeg\\maya\\data\\EMG\\{stage}_Segments\\{group_names[idx]}\\{id}\\left_right\\channels_{segment_num}_raw.fif\"\n",
    "                raw = mne.io.read_raw_fif(fname, verbose='ERROR')\n",
    "                raw.load_data(verbose='ERROR')\n",
    "                data = raw.get_data(verbose='ERROR')\n",
    "                size = data.shape[1]/250\n",
    "                t = 0\n",
    "                sample_num = 0\n",
    "                while (t + x < size):\n",
    "                    raw.save(rf\"D:\\eeg\\maya\\data\\EMG\\{x}_sec_samples\\{stage}\\{group_names[idx]}\\{id}_{segment_num}_{sample_num}_raw.fif\", \n",
    "                            tmin = t, \n",
    "                            tmax = t + x,\n",
    "                            verbose='ERROR')\n",
    "                    t+=x\n",
    "                    sample_num+=1\n",
    "            #The commented code below adds the reminder of the segment that is less than a second long as a seperate segment. After some considiration, we decided it would be better to omit these samples. \n",
    "                # raw.save(rf\"D:\\eeg\\maya\\data\\EMG\\{x}_sec_samples\\{stage}\\{group_names[idx]}\\{id}_{segment_num}_{sample_num}_raw.fif\", \n",
    "                #             tmin = t, \n",
    "                #             tmax = size,\n",
    "                #             verbose='ERROR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_zeros(signal):\n",
    "    return not np.any(signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_mostly_zeros(signal):\n",
    "    ''' Check whether most of the signal is a sequence of 0's '''\n",
    "    size = len(signal)\n",
    "    max_zeros = 0\n",
    "    count = 0\n",
    "    for i in range(size):\n",
    "        if signal[i] == 0:\n",
    "            count+=1\n",
    "            if count > max_zeros:\n",
    "                max_zeros = count\n",
    "        else:\n",
    "            count = 0\n",
    "    return max_zeros>=size/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(sig1, sig2,prop_1,prop_2, func):\n",
    "    return (func(sig1)*prop_1 + func(sig2)*prop_2)/(prop_1+prop_2)\n",
    "\n",
    "def normalize_diff(sig1, sig2,prop_1,prop_2, func):\n",
    "    abs_diff = abs(func(sig1)-func(sig2))\n",
    "    return abs_diff/normalize(sig1, sig2,prop_1,prop_2, func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abs_mean(arr):\n",
    "    return (np.mean(np.abs(arr)))\n",
    "\n",
    "def zero_crossing_rate(sig):\n",
    "    crossings = 0\n",
    "    l = len(sig)\n",
    "    for i in range(1, l):\n",
    "        if (sig[i-1] >= 0 and sig[i] < 0) or (sig[i-1] < 0 and sig[i] >= 0):\n",
    "            crossings += 1\n",
    "    return crossings / (l - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_peak_to_peak(sample):\n",
    "    return max(sample)-min(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subject_peak_to_peak(path, subject, normalized = True):\n",
    "    maxi = max_1 = max_2 = float('-inf')\n",
    "    mini = min_1 = min_2 = float('inf')\n",
    "    for filename in os.listdir(path):\n",
    "        #check whether file belongs to subject\n",
    "        arr = filename.split('_')\n",
    "        if arr[0]!=subject:\n",
    "            continue    \n",
    "        #if so, open file\n",
    "        f = os.path.join(path, filename)\n",
    "        raw = mne.io.read_raw_fif(f, verbose='ERROR')\n",
    "        sig1, sig2 = raw.get_data()\n",
    "        if is_zeros(sig1) or is_zeros(sig2):\n",
    "            continue\n",
    "        if normalized:\n",
    "            sig1 = zscore(sig1)\n",
    "            sig2 = zscore(sig2)\n",
    "\n",
    "        #look for max and min value over all REM samples\n",
    "        curr_max_1 = max(sig1)\n",
    "        curr_max_2 = max(sig2)\n",
    "        \n",
    "        curr_min_1 = min(sig1)\n",
    "        curr_min_2 = min(sig2)\n",
    "        min_1, max_1 = update_min_max(max_1, min_1, curr_max_1, curr_min_1)\n",
    "        min_2, max_2 = update_min_max(max_2, min_2, curr_max_2, curr_min_2)\n",
    "        curr_max = max(max_1, max_2)\n",
    "        curr_min = min(min_1, min_2)\n",
    "        mini, maxi = update_min_max(maxi, mini, curr_max, curr_min)\n",
    "\n",
    "    return maxi - mini, max_1 - min_1, max_2 - min_2\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_min_max(maxi, mini, curr_max, curr_min):\n",
    "    #print(maxi, mini, curr_max, curr_min)\n",
    "    if maxi < curr_max:\n",
    "        maxi = curr_max\n",
    "    if mini > curr_min:\n",
    "        mini = curr_min\n",
    "    return mini, maxi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 10 #1/5/30 - the sample length used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "REM_c_path = rf\"D:\\eeg\\maya\\data\\EMG\\{x}_sec_samples\\REM\\control\"\n",
    "REM_p_path = rf\"D:\\eeg\\maya\\data\\EMG\\{x}_sec_samples\\REM\\parkinsons\"\n",
    "REM_t_path = rf\"D:\\eeg\\maya\\data\\EMG\\{x}_sec_samples\\REM\\test\"\n",
    "paths = [REM_c_path, REM_p_path]\n",
    "size_c = len(os.listdir(REM_c_path))\n",
    "size_p = len(os.listdir(REM_p_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_to_peak = [[0 for _ in range(20)], [0 for _ in range(23)]]\n",
    "peak_to_peak_diff = [[0 for _ in range(20)], [0 for _ in range(23)]]\n",
    "for num, g in enumerate(groups):\n",
    "    for i, code in enumerate(g):\n",
    "        p2p = subject_peak_to_peak(paths[num], code)\n",
    "        peak_to_peak[num][i] = p2p[0]\n",
    "        peak_to_peak_diff[num][i] = abs(p2p[1]-p2p[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['Subject', 'Group', \n",
    "          'MAV', 'MAV Diff', 'ZCR', 'ZCR Diff','PAV', 'Peak Count', 'Peak Count Diff',\n",
    "          'Peak Amp. diff', 'Mean Peak Amp. Diff', 'Mean Peak Delay', 'STD Peak delay', \n",
    "          'P2P Diff', 'Sub P2P Diff', 'Sub P2P', \n",
    "          'Max Corr', 'Mean Corr', 'mean absolute diff','Norm', 'Pearson'])\n",
    "\n",
    "for group,path in enumerate([REM_c_path, REM_p_path]):\n",
    "    for filename in os.listdir(path):\n",
    "        arr = filename.split('_') \n",
    "        \n",
    "        #extract subject's code and index\n",
    "        sub_code = arr[0]\n",
    "        sub_idx = groups[group].index(sub_code)\n",
    "\n",
    "        #open file\n",
    "        f = os.path.join(path, filename)\n",
    "        raw = mne.io.read_raw_fif(f, verbose='ERROR')\n",
    "        sig1, sig2 = raw.get_data()\n",
    "        if is_mostly_zeros(sig1) or is_mostly_zeros(sig2):\n",
    "            continue\n",
    "        \n",
    "        #Normalization - zscore on signal level\n",
    "        sig1 = zscore(sig1)\n",
    "        sig2 = zscore(sig2)\n",
    "\n",
    "        #find peaks in signal\n",
    "        peak_locs_1, peak_mags_1 = peak_finder(sig1, verbose = 'ERROR') \n",
    "        peak_locs_2, peak_mags_2 = peak_finder(sig2, verbose = 'ERROR') \n",
    "\n",
    "        \n",
    "        MAV = normalize(sig1, sig2, 1, 1, abs_mean)\n",
    "        MAV_diff = normalize_diff(sig1, sig2, 1, 1, abs_mean)\n",
    "\n",
    "        zcr = normalize(sig1, sig2, 1, 1, zero_crossing_rate)\n",
    "        zcr_diff = normalize_diff(sig1, sig2, 1, 1, zero_crossing_rate)\n",
    "        #peak related features\n",
    "        MAVPeak = normalize(peak_mags_1, peak_mags_2, len(peak_locs_1), len(peak_locs_2), abs_mean)\n",
    "        peak_count = normalize(peak_locs_1,peak_locs_2,1,1,len)\n",
    "        peak_count_diff = normalize_diff(peak_locs_1,peak_locs_2,1,1,len)\n",
    "        min_len = min(len(peak_locs_1), len(peak_locs_2))\n",
    "        amp_diff = np.mean((np.abs(np.subtract(peak_mags_1[:min_len],peak_mags_2[:min_len]))))\n",
    "        avg_amp_diff = np.abs(np.mean(peak_mags_1[:min_len])- np.mean(peak_mags_2[:min_len]))\n",
    "        time_diff = np.abs(np.subtract(peak_locs_1[:min_len],peak_locs_2[:min_len]))\n",
    "        avg_delay = np.mean(time_diff)\n",
    "        std_delay = np.std(time_diff)\n",
    "        \n",
    "        p2p_diff = abs(sample_peak_to_peak(sig1)-sample_peak_to_peak(sig2))\n",
    "        sub_p2p = peak_to_peak[group][sub_idx]\n",
    "        sub_p2p_diff = peak_to_peak_diff[group][sub_idx]\n",
    "        \n",
    "        coeff = (np.corrcoef(sig1, sig2)[0][1])\n",
    "        mean_diff = (np.mean(np.abs(sig1 - sig2)))\n",
    "        corr = np.correlate(sig1, sig2, mode='same')\n",
    "        max_corr = max(corr)\n",
    "        mean_corr = np.mean(corr)\n",
    "        d = np.linalg.norm(sig1 - sig2)        \n",
    "\n",
    "        df.loc[len(df)] = [sub_code, group, \n",
    "                           MAV, MAV_diff, zcr, zcr_diff, MAVPeak, peak_count, peak_count_diff, \n",
    "                           amp_diff, avg_amp_diff, avg_delay, std_delay,\n",
    "                           p2p_diff, sub_p2p_diff, sub_p2p,\n",
    "                           max_corr, mean_corr, mean_diff, d, coeff]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Group</th>\n",
       "      <th>MAV</th>\n",
       "      <th>MAV Diff</th>\n",
       "      <th>ZCR</th>\n",
       "      <th>ZCR Diff</th>\n",
       "      <th>PAV</th>\n",
       "      <th>Peak Count</th>\n",
       "      <th>Peak Count Diff</th>\n",
       "      <th>Peak Amp. diff</th>\n",
       "      <th>...</th>\n",
       "      <th>Mean Peak Delay</th>\n",
       "      <th>STD Peak delay</th>\n",
       "      <th>P2P Diff</th>\n",
       "      <th>Sub P2P Diff</th>\n",
       "      <th>Sub P2P</th>\n",
       "      <th>Max Corr</th>\n",
       "      <th>Mean Corr</th>\n",
       "      <th>mean absolute diff</th>\n",
       "      <th>Norm</th>\n",
       "      <th>Pearson</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AA4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.739529</td>\n",
       "      <td>0.054471</td>\n",
       "      <td>0.1798</td>\n",
       "      <td>0.095662</td>\n",
       "      <td>1.782317</td>\n",
       "      <td>80.5</td>\n",
       "      <td>0.335404</td>\n",
       "      <td>0.726628</td>\n",
       "      <td>...</td>\n",
       "      <td>365.776119</td>\n",
       "      <td>172.998906</td>\n",
       "      <td>0.399074</td>\n",
       "      <td>5.985009</td>\n",
       "      <td>34.436445</td>\n",
       "      <td>1539.706148</td>\n",
       "      <td>0.095131</td>\n",
       "      <td>0.686913</td>\n",
       "      <td>43.847323</td>\n",
       "      <td>0.615636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AA4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.759741</td>\n",
       "      <td>0.002793</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.081112</td>\n",
       "      <td>1.793669</td>\n",
       "      <td>86.5</td>\n",
       "      <td>0.104046</td>\n",
       "      <td>0.685964</td>\n",
       "      <td>...</td>\n",
       "      <td>138.682927</td>\n",
       "      <td>90.418657</td>\n",
       "      <td>0.249826</td>\n",
       "      <td>5.985009</td>\n",
       "      <td>34.436445</td>\n",
       "      <td>1406.071737</td>\n",
       "      <td>-0.025471</td>\n",
       "      <td>0.732706</td>\n",
       "      <td>46.795903</td>\n",
       "      <td>0.562204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AA4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.733916</td>\n",
       "      <td>0.007951</td>\n",
       "      <td>0.1896</td>\n",
       "      <td>0.033755</td>\n",
       "      <td>1.858423</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.868716</td>\n",
       "      <td>...</td>\n",
       "      <td>91.960000</td>\n",
       "      <td>58.242582</td>\n",
       "      <td>0.438770</td>\n",
       "      <td>5.985009</td>\n",
       "      <td>34.436445</td>\n",
       "      <td>1470.152994</td>\n",
       "      <td>0.371051</td>\n",
       "      <td>0.706244</td>\n",
       "      <td>45.405881</td>\n",
       "      <td>0.587826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AA4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.722980</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.2126</td>\n",
       "      <td>0.084666</td>\n",
       "      <td>1.910027</td>\n",
       "      <td>70.5</td>\n",
       "      <td>0.297872</td>\n",
       "      <td>0.918352</td>\n",
       "      <td>...</td>\n",
       "      <td>398.833333</td>\n",
       "      <td>220.913193</td>\n",
       "      <td>1.636861</td>\n",
       "      <td>5.985009</td>\n",
       "      <td>34.436445</td>\n",
       "      <td>1710.163009</td>\n",
       "      <td>-0.081499</td>\n",
       "      <td>0.631842</td>\n",
       "      <td>39.770265</td>\n",
       "      <td>0.683792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AA4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.746014</td>\n",
       "      <td>0.013353</td>\n",
       "      <td>0.1950</td>\n",
       "      <td>0.006154</td>\n",
       "      <td>1.810744</td>\n",
       "      <td>83.5</td>\n",
       "      <td>0.107784</td>\n",
       "      <td>0.595421</td>\n",
       "      <td>...</td>\n",
       "      <td>134.240506</td>\n",
       "      <td>108.649153</td>\n",
       "      <td>0.073166</td>\n",
       "      <td>5.985009</td>\n",
       "      <td>34.436445</td>\n",
       "      <td>1535.396915</td>\n",
       "      <td>0.205252</td>\n",
       "      <td>0.709559</td>\n",
       "      <td>43.945491</td>\n",
       "      <td>0.613913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Subject  Group       MAV  MAV Diff     ZCR  ZCR Diff       PAV  Peak Count  \\\n",
       "0     AA4      0  0.739529  0.054471  0.1798  0.095662  1.782317        80.5   \n",
       "1     AA4      0  0.759741  0.002793  0.1726  0.081112  1.793669        86.5   \n",
       "2     AA4      0  0.733916  0.007951  0.1896  0.033755  1.858423        75.0   \n",
       "3     AA4      0  0.722980  0.000657  0.2126  0.084666  1.910027        70.5   \n",
       "4     AA4      0  0.746014  0.013353  0.1950  0.006154  1.810744        83.5   \n",
       "\n",
       "   Peak Count Diff  Peak Amp. diff  ...  Mean Peak Delay  STD Peak delay  \\\n",
       "0         0.335404        0.726628  ...       365.776119      172.998906   \n",
       "1         0.104046        0.685964  ...       138.682927       90.418657   \n",
       "2         0.000000        0.868716  ...        91.960000       58.242582   \n",
       "3         0.297872        0.918352  ...       398.833333      220.913193   \n",
       "4         0.107784        0.595421  ...       134.240506      108.649153   \n",
       "\n",
       "   P2P Diff  Sub P2P Diff    Sub P2P     Max Corr  Mean Corr  \\\n",
       "0  0.399074      5.985009  34.436445  1539.706148   0.095131   \n",
       "1  0.249826      5.985009  34.436445  1406.071737  -0.025471   \n",
       "2  0.438770      5.985009  34.436445  1470.152994   0.371051   \n",
       "3  1.636861      5.985009  34.436445  1710.163009  -0.081499   \n",
       "4  0.073166      5.985009  34.436445  1535.396915   0.205252   \n",
       "\n",
       "   mean absolute diff       Norm   Pearson  \n",
       "0            0.686913  43.847323  0.615636  \n",
       "1            0.732706  46.795903  0.562204  \n",
       "2            0.706244  45.405881  0.587826  \n",
       "3            0.631842  39.770265  0.683792  \n",
       "4            0.709559  43.945491  0.613913  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Group</th>\n",
       "      <th>MAV</th>\n",
       "      <th>MAV Diff</th>\n",
       "      <th>ZCR</th>\n",
       "      <th>ZCR Diff</th>\n",
       "      <th>PAV</th>\n",
       "      <th>Peak Count</th>\n",
       "      <th>Peak Count Diff</th>\n",
       "      <th>Peak Amp. diff</th>\n",
       "      <th>...</th>\n",
       "      <th>Mean Peak Delay</th>\n",
       "      <th>STD Peak delay</th>\n",
       "      <th>P2P Diff</th>\n",
       "      <th>Sub P2P Diff</th>\n",
       "      <th>Sub P2P</th>\n",
       "      <th>Max Corr</th>\n",
       "      <th>Mean Corr</th>\n",
       "      <th>mean absolute diff</th>\n",
       "      <th>Norm</th>\n",
       "      <th>Pearson</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14450</th>\n",
       "      <td>ZZ0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.762075</td>\n",
       "      <td>0.016777</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.055734</td>\n",
       "      <td>1.697270</td>\n",
       "      <td>189.0</td>\n",
       "      <td>0.137566</td>\n",
       "      <td>0.719525</td>\n",
       "      <td>...</td>\n",
       "      <td>101.914773</td>\n",
       "      <td>55.255384</td>\n",
       "      <td>1.248981</td>\n",
       "      <td>12.157826</td>\n",
       "      <td>46.961829</td>\n",
       "      <td>946.725425</td>\n",
       "      <td>0.198635</td>\n",
       "      <td>0.855561</td>\n",
       "      <td>55.754364</td>\n",
       "      <td>0.378539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14451</th>\n",
       "      <td>ZZ0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.786873</td>\n",
       "      <td>0.016812</td>\n",
       "      <td>0.4250</td>\n",
       "      <td>0.036706</td>\n",
       "      <td>1.538453</td>\n",
       "      <td>243.0</td>\n",
       "      <td>0.238683</td>\n",
       "      <td>0.640439</td>\n",
       "      <td>...</td>\n",
       "      <td>184.308411</td>\n",
       "      <td>116.711595</td>\n",
       "      <td>0.749368</td>\n",
       "      <td>12.157826</td>\n",
       "      <td>46.961829</td>\n",
       "      <td>729.333406</td>\n",
       "      <td>-0.002327</td>\n",
       "      <td>0.946792</td>\n",
       "      <td>59.525904</td>\n",
       "      <td>0.291617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14452</th>\n",
       "      <td>ZZ0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.779659</td>\n",
       "      <td>0.006549</td>\n",
       "      <td>0.3936</td>\n",
       "      <td>0.010163</td>\n",
       "      <td>1.664057</td>\n",
       "      <td>189.0</td>\n",
       "      <td>0.137566</td>\n",
       "      <td>0.601009</td>\n",
       "      <td>...</td>\n",
       "      <td>132.278409</td>\n",
       "      <td>93.060200</td>\n",
       "      <td>0.484677</td>\n",
       "      <td>12.157826</td>\n",
       "      <td>46.961829</td>\n",
       "      <td>625.530676</td>\n",
       "      <td>-0.057192</td>\n",
       "      <td>0.962994</td>\n",
       "      <td>61.244907</td>\n",
       "      <td>0.250112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14453</th>\n",
       "      <td>ZZ0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.660086</td>\n",
       "      <td>0.107501</td>\n",
       "      <td>0.3696</td>\n",
       "      <td>0.093074</td>\n",
       "      <td>2.485919</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.175824</td>\n",
       "      <td>1.076112</td>\n",
       "      <td>...</td>\n",
       "      <td>122.506024</td>\n",
       "      <td>258.807291</td>\n",
       "      <td>1.085649</td>\n",
       "      <td>12.157826</td>\n",
       "      <td>46.961829</td>\n",
       "      <td>262.697743</td>\n",
       "      <td>0.070079</td>\n",
       "      <td>0.881028</td>\n",
       "      <td>69.697199</td>\n",
       "      <td>0.028849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14454</th>\n",
       "      <td>ZZ0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.781087</td>\n",
       "      <td>0.019957</td>\n",
       "      <td>0.4478</td>\n",
       "      <td>0.152747</td>\n",
       "      <td>1.645060</td>\n",
       "      <td>229.5</td>\n",
       "      <td>0.065359</td>\n",
       "      <td>0.632667</td>\n",
       "      <td>...</td>\n",
       "      <td>88.126126</td>\n",
       "      <td>64.086248</td>\n",
       "      <td>0.391919</td>\n",
       "      <td>12.157826</td>\n",
       "      <td>46.961829</td>\n",
       "      <td>382.957809</td>\n",
       "      <td>0.049007</td>\n",
       "      <td>1.023833</td>\n",
       "      <td>65.085209</td>\n",
       "      <td>0.153122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Subject  Group       MAV  MAV Diff     ZCR  ZCR Diff       PAV  \\\n",
       "14450     ZZ0      1  0.762075  0.016777  0.3732  0.055734  1.697270   \n",
       "14451     ZZ0      1  0.786873  0.016812  0.4250  0.036706  1.538453   \n",
       "14452     ZZ0      1  0.779659  0.006549  0.3936  0.010163  1.664057   \n",
       "14453     ZZ0      1  0.660086  0.107501  0.3696  0.093074  2.485919   \n",
       "14454     ZZ0      1  0.781087  0.019957  0.4478  0.152747  1.645060   \n",
       "\n",
       "       Peak Count  Peak Count Diff  Peak Amp. diff  ...  Mean Peak Delay  \\\n",
       "14450       189.0         0.137566        0.719525  ...       101.914773   \n",
       "14451       243.0         0.238683        0.640439  ...       184.308411   \n",
       "14452       189.0         0.137566        0.601009  ...       132.278409   \n",
       "14453        91.0         0.175824        1.076112  ...       122.506024   \n",
       "14454       229.5         0.065359        0.632667  ...        88.126126   \n",
       "\n",
       "       STD Peak delay  P2P Diff  Sub P2P Diff    Sub P2P    Max Corr  \\\n",
       "14450       55.255384  1.248981     12.157826  46.961829  946.725425   \n",
       "14451      116.711595  0.749368     12.157826  46.961829  729.333406   \n",
       "14452       93.060200  0.484677     12.157826  46.961829  625.530676   \n",
       "14453      258.807291  1.085649     12.157826  46.961829  262.697743   \n",
       "14454       64.086248  0.391919     12.157826  46.961829  382.957809   \n",
       "\n",
       "       Mean Corr  mean absolute diff       Norm   Pearson  \n",
       "14450   0.198635            0.855561  55.754364  0.378539  \n",
       "14451  -0.002327            0.946792  59.525904  0.291617  \n",
       "14452  -0.057192            0.962994  61.244907  0.250112  \n",
       "14453   0.070079            0.881028  69.697199  0.028849  \n",
       "14454   0.049007            1.023833  65.085209  0.153122  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(rf\"D:\\eeg\\maya\\data\\features_{x}s.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sub_code = group_names[group].index('AA4')\n",
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This method seperates the data into a training set and a test set with x:(1-x) \n",
    "proportions such that each subject's samples are either all in the training \n",
    "set or all in the test set'''\n",
    "\n",
    "import itertools\n",
    "\n",
    "def find_closest_subarrays(set1, set2, x):\n",
    "    total_set1 = sum(set1)\n",
    "    total_set2 = sum(set2)\n",
    "    m = min(total_set1, total_set2)\n",
    "    target_sum = m * x\n",
    "\n",
    "    closest_sum_set1 = float('inf')\n",
    "    closest_subarray_set1 = []\n",
    "\n",
    "    for r in range(1, len(set1) + 1):\n",
    "        for indices in itertools.combinations(range(len(set1)), r):\n",
    "            subgroup = [set1[i] for i in indices]\n",
    "            subarray_sum = sum(subgroup)\n",
    "            if abs(subarray_sum - target_sum) < abs(closest_sum_set1 - target_sum):\n",
    "                closest_sum_set1 = subarray_sum\n",
    "                closest_subarray_set1 = np.asarray(indices)\n",
    "\n",
    "    closest_sum_set2 = float('inf')\n",
    "    closest_subarray_set2 = []\n",
    "\n",
    "    for r in range(1, len(set2) + 1):\n",
    "        for indices in itertools.combinations(range(len(set2)), r):\n",
    "            subgroup = [set2[i] for i in indices]\n",
    "            subarray_sum = sum(subgroup)\n",
    "            if abs(subarray_sum - target_sum) < abs(closest_sum_set2 - target_sum):\n",
    "                closest_sum_set2 = subarray_sum\n",
    "                closest_subarray_set2 = np.asarray(indices)\n",
    "\n",
    "    return closest_subarray_set1, closest_subarray_set2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2814b4ccc6419ff0c4aa2f5156bbb668f4ebe07c0be8afa2ebb03dd91d03eab5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
